# Muni Metro Subway Status

Is the Muni Metro subway in San Francisco running? This web app monitors the internal status image and provides a brief summary using computer vision.

See it in action:
https://munimet.ro

This project was largely "vibe coded" using Anthropic's Claude Code. The project itself does not rely on Claude or any other LLM AI.

## Quick Start

### For New Users (First Time Setup)

This project uses **git-annex** to manage large files (1.1GB of training data and models) stored in Google Cloud Storage.

```bash
# 1. Clone the repository
git clone <your-repo-url>
cd munimetro

# 2. Set up git-annex and download data (see artifacts/README.md)
brew install git-annex rclone git-annex-remote-rclone
git annex init "your-laptop"
git annex enableremote google-cloud
git annex get artifacts/models/v1/        # Download model (856MB)

# 3. Train the model (see training/README.md)
cd training
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
python download_muni_image.py  # Collect data
python label_images.py          # Label images
python train_model.py           # Train model

# 4. Run the API (see api/README.md)
cd ../api
docker-compose up -d
open http://localhost:8000
```

See **[artifacts/README.md](artifacts/README.md)** for complete data management workflow.

## Project Structure

```
munimetro/
â”œâ”€â”€ lib/                    # Shared library code
â”‚   â””â”€â”€ muni_lib.py        # Core functions for download & prediction
â”‚
â”œâ”€â”€ training/              # Data collection & ML training â†’ See training/README.md
â”‚   â”œâ”€â”€ download_muni_image.py  # Download status images
â”‚   â”œâ”€â”€ label_images.py         # GUI for labeling images
â”‚   â”œâ”€â”€ train_model.py          # Train BLIP vision-language model
â”‚   â””â”€â”€ requirements.txt        # ML dependencies
â”‚
â”œâ”€â”€ api/                   # Production web API & deployment â†’ See api/README.md
â”‚   â”œâ”€â”€ api.py             # Falcon web API
â”‚   â”œâ”€â”€ check_status.py    # Download + predict combined
â”‚   â”œâ”€â”€ predict_status.py  # Standalone prediction script
â”‚   â”œâ”€â”€ index.html         # Web dashboard (8.6KB, vanilla JS)
â”‚   â”œâ”€â”€ Dockerfile         # Production container image
â”‚   â””â”€â”€ docker-compose.yml # Local deployment orchestration
â”‚
â”œâ”€â”€ tests/                 # Test suite â†’ See tests/README.md
â”‚   â””â”€â”€ test_frontend.py   # Frontend integration tests
â”‚
â””â”€â”€ artifacts/             # Generated data â†’ See artifacts/README.md
    â”œâ”€â”€ training_data/     # ML training dataset (git-annex tracked)
    â”‚   â”œâ”€â”€ images/        # 2,666 labeled snapshots (~270MB)
    â”‚   â””â”€â”€ labels.json    # Training labels (570KB, unlocked)
    â”œâ”€â”€ models/            # Trained models (git-annex tracked)
    â”‚   â””â”€â”€ v1/            # BLIP model + classifier (856MB)
    â””â”€â”€ runtime/           # Transient runtime data (gitignored)
        â”œâ”€â”€ cache/         # API response cache
        â””â”€â”€ downloads/     # Recent snapshots for predictions
```

## Documentation

- **[Data Management](artifacts/README.md)** - Git-annex workflows for training data and models
- **[Training Guide](training/README.md)** - Download images, label data, train models
- **[API & Deployment](api/README.md)** - Run API locally or deploy to Google Cloud Run
- **[Testing](tests/README.md)** - Run automated tests
- **[Setup](SETUP.md)** - Virtual environment setup and troubleshooting
- **[GCS Setup](GCS_SETUP.md)** - Initial Google Cloud Storage configuration

## Workflow

1. **Data Collection** - Run `download_muni_image.py` to collect status images over time
2. **Labeling** - Use `label_images.py` GUI to label 50-100+ images with status + descriptions
3. **Training** - Run `train_model.py` to fine-tune BLIP model on your labeled data
4. **Deployment** - Use Docker to deploy the API locally or to Google Cloud Run
5. **Monitoring** - Access real-time status via web dashboard or API endpoints

## Features

- **ML-Powered Classification** - BLIP vision-language model classifies status (ðŸŸ¢/ðŸŸ¡/ðŸ”´) and generates descriptions
- **Production-Ready API** - Falcon web framework with health checks, caching, and graceful degradation
- **Lightweight Frontend** - 8.6KB vanilla JavaScript dashboard with zero dependencies
- **Containerized Deployment** - Multi-stage Docker build with security best practices
- **Smart Caching** - Best-of-two status logic smooths transient failures (~30ms response time)

## Requirements

- **Training**: Python 3.13+, PyTorch, Transformers, Pillow, tkinter
- **API**: Docker & Docker Compose (or Python 3.13+ for local development)
- **Cloud Deployment**: Google Cloud SDK (optional)
- **Data Management**: git-annex (for accessing training data/models from cloud storage)

## License

MIT
